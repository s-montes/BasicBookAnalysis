---
title: "Basic statistical book analysis"
output: html_notebook
---

## Libraries

```{r}
library(tidyverse)
library(ggplot2)
library(textstem)
library(tidytext)
library(scales)
library(wordcloud)
library(reshape2)
```

## Load book

We will use * Frankenstein; or, the Modern Prometheus*, by Mary Shelley ([Gutenberg Project](http://www.gutenberg.org/ebooks/84)):

```{r}
raw_book <- list.files(path = "./", pattern = "Frankenstein.txt", full.names = T) %>% 
        map_chr(~ read_file(.)) %>% 
        str_replace_all("â€™", "'") %>% 
        str_replace_all("'s\\b", "") %>% 
        data_frame(text = .)

## In case we are analyzing several books at once:
## Enumerate books
# raw_book <- raw_book %>% 
#   mutate(linenumber = row_number(),
#          book = cumsum(str_detect(text, regex("^NP: .+",
#                                                  ignore_case = TRUE)))) %>%
#   ungroup()

# Tidy book by tokenizing
tidy_book <- raw_book %>%
  unnest_tokens(word, text) 

# Load stop words in English
data(stop_words)

# Remove stop words
tidy_book <- tidy_book %>%
  anti_join(stop_words)
```

## Lemmatize book

Find the lemma for all the words:

```{r}
lemma_book <- tidy_book %>% 
  mutate(word = lemmatize_words(word))
```

```{r}
tidy_book %>%
  count(word, sort = TRUE) 
```

```{r}
lemma_book %>%
  count(word, sort = TRUE) 
```

## Sentiment analysis

Score each word according to the general lexicon from [Bing Liu and collaborators](https://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html)

```{r}
lemma_book %>%
  inner_join(get_sentiments("bing")) %>%
  count(word, sentiment, sort = TRUE) %>%
  acast(word ~ sentiment, value.var = "n", fill = 0) %>%
  comparison.cloud(colors = c("rosybrown4", "black"),
                   max.words = 40)
```

Count the most common positive and negative words (after lemmatization)

```{r}
lemma_book %>%
  inner_join(get_sentiments("bing")) %>%
  count(word, sentiment, sort = TRUE) %>%
  ungroup() %>% group_by(sentiment) %>%
  top_n(10) %>%
  ungroup() %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(word, n, fill = sentiment)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~sentiment, scales = "free_y") +
  labs(title = 'Most common positive and negative words',
       y = "Contribution to sentiment",
       x = NULL) +
  scale_fill_manual( values = c("red", "purple")) +
  coord_flip()
```